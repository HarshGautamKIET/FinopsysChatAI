#!/usr/bin/env python3
"""
Test script for OpenAI integration
Tests the LLMManager with OpenAI support
"""

import os
import sys
sys.path.insert(0, '.')

# Fix import path for LLMManager
sys.path.insert(0, './streamlit/src')
from app import LLMManager
from config import Config
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_openai_integration():
    """Test OpenAI integration with the LLMManager"""
    print("ğŸ§ª Testing OpenAI Integration...")
    
    # Load config
    config = Config()
    
    # Check if OpenAI API key is available
    openai_key = config.OPENAI_API_KEY or os.getenv('OPENAI_API_KEY')
    if not openai_key:
        print("âš ï¸  No OpenAI API key found. Please set OPENAI_API_KEY in .env")
        print("   This test will verify the code structure only.")
    
    # Initialize LLM Manager
    llm_manager = LLMManager()
    
    # Test initialization
    print("\nğŸ“‹ Testing LLM Manager Initialization...")
    success = llm_manager.initialize_models()
    
    if success:
        print("âœ… LLM Manager initialized successfully")
        print(f"ğŸ”— Available providers: {llm_manager.available_providers}")
        print(f"ğŸ¯ Active provider: {llm_manager.active_provider}")
        
        # Test provider switching
        if 'openai' in llm_manager.available_providers:
            print("\nğŸ”„ Testing OpenAI Provider Switch...")
            if llm_manager.set_active_provider('openai'):
                print("âœ… Successfully switched to OpenAI")
                
                # Test a simple response
                if openai_key:
                    print("\nğŸ’¬ Testing OpenAI Response Generation...")
                    try:
                        response = llm_manager.generate_response("What is 2+2?")
                        print(f"ğŸ“ OpenAI Response: {response[:100]}...")
                        print("âœ… OpenAI response generation successful")
                    except Exception as e:
                        print(f"âŒ OpenAI response generation failed: {str(e)}")
                else:
                    print("âš ï¸  Skipping response test (no API key)")
            else:
                print("âŒ Failed to switch to OpenAI")
        else:
            print("âš ï¸  OpenAI provider not available")
            
        # Test fallback mechanism
        print("\nğŸ”„ Testing Provider Fallback...")
        original_provider = llm_manager.active_provider
        
        # Try switching to each available provider
        for provider in llm_manager.available_providers:
            if llm_manager.set_active_provider(provider):
                display_name = llm_manager.get_provider_display_name(provider)
                print(f"âœ… Successfully switched to {display_name}")
            else:
                print(f"âŒ Failed to switch to {provider}")
        
        # Restore original provider
        llm_manager.set_active_provider(original_provider)
        
    else:
        print("âŒ LLM Manager initialization failed")
        return False
    
    print("\nğŸ‰ OpenAI Integration Test Completed!")
    return True

def test_configuration():
    """Test configuration for OpenAI"""
    print("\nâš™ï¸  Testing Configuration...")
    
    config = Config()
    
    print(f"ğŸ“ OpenAI Model: {config.OPENAI_MODEL}")
    print(f"ğŸ”‘ OpenAI API Key: {'âœ… Set' if config.OPENAI_API_KEY else 'âŒ Not Set'}")
    print(f"ğŸ¯ Default Provider: {config.DEFAULT_PROVIDER}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ FinOpSysAI - OpenAI Integration Test")
    print("=" * 50)
    
    try:
        # Test configuration
        test_configuration()
        
        # Test OpenAI integration
        test_openai_integration()
        
        print("\nâœ… All tests completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
