import sys
import os

# Add parent directory to path for imports
current_file = os.path.abspath(__file__)
project_root = os.path.dirname(current_file)
sys.path.insert(0, project_root)

# Import the LLMManager (we'll need to mock streamlit session state)
class MockSessionState:
    def __init__(self):
        self.selected_model = "gpt-4o-mini"
    
    def get(self, key, default=None):
        return getattr(self, key, default)

# Mock streamlit for testing
import streamlit as st
st.session_state = MockSessionState()

# Now import and test the LLMManager
sys.path.insert(0, os.path.join(project_root, 'streamlit', 'src'))

# Set up configuration
from config import Config
config = Config()
print("‚úÖ Configuration loaded")

# Test initialization
print("üîç Testing LLM Manager initialization...")
try:
    # We'll test just the initialization logic without full Streamlit context
    print(f"‚úÖ OpenAI API Key configured: {'Yes' if config.OPENAI_API_KEY else 'No'}")
    print(f"‚úÖ Gemini API Key configured: {'Yes' if config.GEMINI_API_KEY else 'No'}")
    print(f"‚úÖ Default Provider: {config.DEFAULT_PROVIDER}")
    print(f"‚úÖ Default Model: {config.DEFAULT_MODEL}")
    print(f"‚úÖ Available OpenAI Models: {config.OPENAI_MODELS}")
    print(f"‚úÖ Available Gemini Models: {config.GEMINI_MODELS}")
    
    print("\n‚úÖ Multi-provider AI system configuration test completed successfully!")
    
except Exception as e:
    print(f"‚ùå Configuration test failed: {e}")
    sys.exit(1)
