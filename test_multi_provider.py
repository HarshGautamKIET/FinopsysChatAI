#!/usr/bin/env python3
"""
Enhanced Multi-Provider LLM Test
Tests all three providers: Gemini, OpenAI, and Ollama
"""

import os
import sys
sys.path.insert(0, '.')
sys.path.insert(0, './streamlit/src')

from app import LLMManager
from config import Config
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_all_providers():
    """Test all available LLM providers"""
    print("ğŸš€ FinOpSysAI - Multi-Provider LLM Test")
    print("=" * 50)
    
    # Initialize config
    config = Config()
    
    print("âš™ï¸  Testing Configuration...")
    print(f"ğŸ“ Gemini Model: {config.DEFAULT_MODEL}")
    print(f"ğŸ“ OpenAI Model: {config.OPENAI_MODEL}")
    print(f"ğŸ“ Ollama Model: {config.OLLAMA_MODEL}")
    print(f"ğŸ”‘ Gemini API Key: {'âœ… Set' if config.GEMINI_API_KEY else 'âŒ Not Set'}")
    print(f"ğŸ”‘ OpenAI API Key: {'âœ… Set' if config.OPENAI_API_KEY else 'âŒ Not Set'}")
    print(f"ğŸ¯ Default Provider: {config.DEFAULT_PROVIDER}")
    
    print("\nğŸ§ª Testing Multi-Provider Integration...")
    
    # Initialize LLM Manager
    llm_manager = LLMManager()
    
    print("ğŸ“‹ Testing LLM Manager Initialization...")
    success = llm_manager.initialize_models()
    
    if success:
        print("âœ… LLM Manager initialized successfully")
        print(f"ğŸ”— Available providers: {llm_manager.available_providers}")
        print(f"ğŸ¯ Active provider: {llm_manager.active_provider}")
        
        # Test each available provider
        for provider in llm_manager.available_providers:
            print(f"\nğŸ”„ Testing {provider.upper()} Provider...")
            
            # Switch to provider
            if llm_manager.set_active_provider(provider):
                display_name = llm_manager.get_provider_display_name(provider)
                print(f"âœ… Successfully switched to {display_name}")
                
                # Test response generation
                try:
                    response = llm_manager.generate_response("What is 2+2? Answer briefly.")
                    if response and not response.startswith("âŒ"):
                        print(f"ğŸ“ {provider.upper()} Response: {response[:100]}...")
                        print(f"âœ… {provider.upper()} response generation successful")
                    else:
                        print(f"âŒ {provider.upper()} response generation failed")
                except Exception as e:
                    print(f"âŒ {provider.upper()} test failed: {str(e)}")
            else:
                print(f"âŒ Failed to switch to {provider}")
        
        print("\nğŸ”„ Testing Provider Switching...")
        # Test switching between providers
        for provider in llm_manager.available_providers:
            if llm_manager.set_active_provider(provider):
                display_name = llm_manager.get_provider_display_name(provider)
                print(f"âœ… Successfully switched to {display_name}")
        
        print("\nğŸ‰ Multi-Provider LLM Test Completed!")
        print("âœ… All tests completed successfully!")
        
        # Display summary
        print("\nğŸ“Š Test Summary:")
        print(f"   ğŸ”— Available Providers: {len(llm_manager.available_providers)}")
        for provider in llm_manager.available_providers:
            display_name = llm_manager.get_provider_display_name(provider)
            print(f"   - {display_name}")
        
    else:
        print("âŒ LLM Manager initialization failed")
        print("âš ï¸  Please check your API keys and network connectivity")

if __name__ == "__main__":
    test_all_providers()
