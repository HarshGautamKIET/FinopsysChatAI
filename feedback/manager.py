"""
Feedback Management System
Handles storage, retrieval, and analysis of developer feedback
"""
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict

from .vector_store import feedback_store

logger = logging.getLogger(__name__)

@dataclass
class DeveloperFeedback:
    """Structure for developer feedback"""
    is_helpful: bool
    correction: Optional[str] = None
    improvement_suggestion: Optional[str] = None
    category: Optional[str] = None  # e.g., "pricing", "query_accuracy", "response_format"
    severity: int = 1  # 1-5 scale (for negative feedback)
    
    # For positive feedback
    positive_aspects: Optional[str] = None  # What was done well
    good_example_type: Optional[str] = None  # Type of good example (query_structure, response_format, data_accuracy, etc.)
    quality_rating: int = 3  # 1-5 scale for overall quality (for positive feedback)
    reusable_pattern: Optional[str] = None  # Pattern that can be reused for similar queries

@dataclass
class FeedbackItem:
    """Complete feedback item structure"""
    id: str
    original_prompt: str
    original_response: str
    developer_feedback: DeveloperFeedback
    vendor_id: Optional[str] = None
    case_id: Optional[str] = None
    sql_query: Optional[str] = None
    query_type: Optional[str] = None  # e.g., "item_query", "financial_query"
    created_at: str = None
    updated_at: str = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()
        if self.updated_at is None:
            self.updated_at = datetime.now().isoformat()

class FeedbackManager:
    """Main feedback management class"""
    
    def __init__(self):
        self.store = feedback_store
        self.development_mode = False  # Will be set by config
    
    def set_development_mode(self, enabled: bool):
        """Enable or disable development mode"""
        self.development_mode = enabled
        logger.info(f"Development mode {'enabled' if enabled else 'disabled'}")
    
    def submit_feedback(self, 
                       original_prompt: str,
                       original_response: str,
                       is_helpful: bool,
                       correction: Optional[str] = None,
                       improvement_suggestion: Optional[str] = None,
                       category: Optional[str] = None,
                       severity: int = 1,
                       vendor_id: Optional[str] = None,
                       case_id: Optional[str] = None,
                       sql_query: Optional[str] = None,
                       query_type: Optional[str] = None,
                       # New parameters for positive feedback
                       positive_aspects: Optional[str] = None,
                       good_example_type: Optional[str] = None,
                       quality_rating: int = 3,
                       reusable_pattern: Optional[str] = None) -> bool:
        """Submit new feedback"""
        
        try:
            # Create feedback structures
            dev_feedback = DeveloperFeedback(
                is_helpful=is_helpful,
                correction=correction,
                improvement_suggestion=improvement_suggestion,
                category=category,
                severity=severity,
                positive_aspects=positive_aspects,
                good_example_type=good_example_type,
                quality_rating=quality_rating,
                reusable_pattern=reusable_pattern
            )
            
            feedback_item = FeedbackItem(
                id="",  # Will be generated by vector store
                original_prompt=original_prompt,
                original_response=original_response,
                developer_feedback=dev_feedback,
                vendor_id=vendor_id,
                case_id=case_id,
                sql_query=sql_query,
                query_type=query_type
            )
            
            # Convert to dict for storage
            feedback_data = {
                "original_prompt": feedback_item.original_prompt,
                "original_response": feedback_item.original_response,
                "developer_feedback": asdict(feedback_item.developer_feedback),
                "vendor_id": feedback_item.vendor_id,
                "case_id": feedback_item.case_id,
                "sql_query": feedback_item.sql_query,
                "query_type": feedback_item.query_type
            }
            
            # Store in vector database
            success = self.store.store_feedback(feedback_data)
            
            if success:
                logger.info(f"Successfully submitted feedback for prompt: {original_prompt[:50]}...")
            else:
                logger.error("Failed to submit feedback")
            
            return success
            
        except Exception as e:
            logger.error(f"Error submitting feedback: {str(e)}")
            return False
    
    def get_relevant_feedback(self, prompt: str, limit: int = 3) -> List[Dict[str, Any]]:
        """Get relevant feedback for a given prompt"""
        if not self.development_mode:
            return []
        
        try:
            similar_feedback = self.store.search_similar_feedback(prompt, limit * 2)  # Get more to filter
            
            # Prioritize helpful feedback but include both positive and negative
            helpful_feedback = []
            corrective_feedback = []
            
            for feedback in similar_feedback:
                is_helpful = feedback.get("developer_feedback", {}).get("is_helpful", False)
                if is_helpful:
                    helpful_feedback.append(feedback)
                else:
                    corrective_feedback.append(feedback)
            
            # Return a mix: prioritize positive examples but include some corrective feedback
            result = helpful_feedback[:max(1, limit - 1)]  # At least 1 positive if available
            if len(result) < limit and corrective_feedback:
                result.extend(corrective_feedback[:limit - len(result)])
            
            return result[:limit]
            
        except Exception as e:
            logger.error(f"Error getting relevant feedback: {str(e)}")
            return []
    
    def get_positive_examples(self, prompt: str, query_type: Optional[str] = None, limit: int = 3) -> List[Dict[str, Any]]:
        """Get positive feedback examples for learning from successful responses"""
        if not self.development_mode:
            return []
        
        try:
            similar_feedback = self.store.search_similar_feedback(prompt, limit * 3)
            
            # Filter for positive feedback only
            positive_feedback = [
                f for f in similar_feedback 
                if f.get("developer_feedback", {}).get("is_helpful", False)
            ]
            
            # Further filter by query type if specified
            if query_type:
                positive_feedback = [
                    f for f in positive_feedback
                    if f.get("query_type") == query_type
                ]
            
            # Sort by quality rating if available
            positive_feedback.sort(
                key=lambda x: x.get("developer_feedback", {}).get("quality_rating", 0), 
                reverse=True
            )
            
            return positive_feedback[:limit]
            
        except Exception as e:
            logger.error(f"Error getting positive examples: {str(e)}")
            return []
    
    def get_all_feedback_for_review(self, vendor_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get all feedback for developer review"""
        if not self.development_mode:
            return []
        
        try:
            return self.store.get_all_feedback(vendor_id)
        except Exception as e:
            logger.error(f"Error getting feedback for review: {str(e)}")
            return []
    
    def update_feedback_item(self, feedback_id: str, updates: Dict[str, Any]) -> bool:
        """Update an existing feedback item"""
        if not self.development_mode:
            return False
        
        try:
            return self.store.update_feedback(feedback_id, updates)
        except Exception as e:
            logger.error(f"Error updating feedback: {str(e)}")
            return False
    
    def delete_feedback_item(self, feedback_id: str) -> bool:
        """Delete a feedback item"""
        if not self.development_mode:
            return False
        
        try:
            return self.store.delete_feedback(feedback_id)
        except Exception as e:
            logger.error(f"Error deleting feedback: {str(e)}")
            return False
    
    def generate_feedback_prompt_enhancement(self, original_prompt: str) -> str:
        """Generate prompt enhancement based on relevant feedback including positive examples"""
        if not self.development_mode:
            return ""
        
        relevant_feedback = self.get_relevant_feedback(original_prompt, limit=3)
        
        if not relevant_feedback:
            return ""
        
        # Separate positive and corrective feedback
        positive_examples = []
        corrective_guidance = []
        
        for feedback in relevant_feedback:
            dev_feedback = feedback.get("developer_feedback", {})
            
            if dev_feedback.get("is_helpful", False):
                # This is a positive example
                example_parts = []
                if dev_feedback.get("positive_aspects"):
                    example_parts.append(f"Good approach: {dev_feedback['positive_aspects']}")
                if dev_feedback.get("reusable_pattern"):
                    example_parts.append(f"Reusable pattern: {dev_feedback['reusable_pattern']}")
                if dev_feedback.get("good_example_type"):
                    example_parts.append(f"Example type: {dev_feedback['good_example_type']}")
                
                if example_parts:
                    example_text = f"""
**Successful Example (Quality: {dev_feedback.get('quality_rating', 3)}/5):**
Query: {feedback.get('original_prompt', '')[:100]}...
Response approach: {'. '.join(example_parts)}
"""
                    positive_examples.append(example_text)
            else:
                # This is corrective feedback
                if dev_feedback.get("correction"):
                    corrective_guidance.append(f"Avoid: {dev_feedback['correction']}")
                if dev_feedback.get("improvement_suggestion"):
                    corrective_guidance.append(f"Improve by: {dev_feedback['improvement_suggestion']}")
        
        # Build enhancement text
        enhancement_parts = []
        
        if positive_examples:
            enhancement_parts.append("**SUCCESSFUL EXAMPLES TO FOLLOW:**")
            enhancement_parts.extend(positive_examples)
        
        if corrective_guidance:
            enhancement_parts.append("**IMPORTANT GUIDELINES:**")
            enhancement_parts.extend(f"- {guidance}" for guidance in corrective_guidance)
        
        if enhancement_parts:
            enhancement_text = f"""
Previous Developer Feedback for Similar Queries:
\"\"\"
{chr(10).join(enhancement_parts)}
\"\"\"

Please follow the successful patterns shown above and incorporate these guidelines in your response.
"""
            return enhancement_text
        
        return ""
    
    def get_feedback_statistics(self) -> Dict[str, Any]:
        """Get comprehensive feedback statistics including positive examples"""
        if not self.development_mode:
            return {"error": "Development mode not enabled"}
        
        try:
            stats = self.store.get_feedback_statistics()
            
            # Add positive feedback specific statistics
            all_feedback = self.store.get_all_feedback()
            
            positive_feedback = [
                f for f in all_feedback 
                if f.get("developer_feedback", {}).get("is_helpful", False)
            ]
            
            negative_feedback = [
                f for f in all_feedback 
                if not f.get("developer_feedback", {}).get("is_helpful", True)
            ]
            
            # Calculate quality metrics
            quality_ratings = [
                f.get("developer_feedback", {}).get("quality_rating", 0)
                for f in positive_feedback
                if f.get("developer_feedback", {}).get("quality_rating")
            ]
            
            # Count example types
            example_types = {}
            for feedback in positive_feedback:
                example_type = feedback.get("developer_feedback", {}).get("good_example_type")
                if example_type:
                    example_types[example_type] = example_types.get(example_type, 0) + 1
            
            # Enhanced statistics
            enhanced_stats = {
                **stats,
                "positive_feedback_count": len(positive_feedback),
                "negative_feedback_count": len(negative_feedback),
                "positive_feedback_ratio": len(positive_feedback) / len(all_feedback) if all_feedback else 0,
                "average_quality_rating": sum(quality_ratings) / len(quality_ratings) if quality_ratings else 0,
                "example_types_distribution": example_types,
                "total_reusable_patterns": len([
                    f for f in positive_feedback 
                    if f.get("developer_feedback", {}).get("reusable_pattern")
                ])
            }
            
            return enhanced_stats
            
        except Exception as e:
            logger.error(f"Error getting feedback statistics: {str(e)}")
            return {"error": str(e)}
    
    def export_positive_examples(self, query_type: Optional[str] = None) -> Dict[str, Any]:
        """Export positive examples for training or reference"""
        if not self.development_mode:
            return {"error": "Development mode not enabled"}
        
        try:
            all_feedback = self.store.get_all_feedback()
            
            positive_feedback = [
                f for f in all_feedback 
                if f.get("developer_feedback", {}).get("is_helpful", False)
            ]
            
            if query_type:
                positive_feedback = [
                    f for f in positive_feedback
                    if f.get("query_type") == query_type
                ]
            
            # Sort by quality rating
            positive_feedback.sort(
                key=lambda x: x.get("developer_feedback", {}).get("quality_rating", 0), 
                reverse=True
            )
            
            # Format for export
            exported_examples = []
            for feedback in positive_feedback:
                dev_feedback = feedback.get("developer_feedback", {})
                
                example = {
                    "query": feedback.get("original_prompt"),
                    "response": feedback.get("original_response"),
                    "sql_query": feedback.get("sql_query"),
                    "query_type": feedback.get("query_type"),
                    "quality_rating": dev_feedback.get("quality_rating"),
                    "positive_aspects": dev_feedback.get("positive_aspects"),
                    "good_example_type": dev_feedback.get("good_example_type"),
                    "reusable_pattern": dev_feedback.get("reusable_pattern"),
                    "created_at": feedback.get("created_at")
                }
                
                exported_examples.append(example)
            
            return {
                "success": True,
                "total_examples": len(exported_examples),
                "query_type_filter": query_type,
                "examples": exported_examples
            }
            
        except Exception as e:
            logger.error(f"Error exporting positive examples: {str(e)}")
            return {"error": str(e)}

    def find_similar_feedback(self, prompt: str, response: str) -> Optional[Dict[str, Any]]:
        """Find existing feedback for similar prompt/response to prevent duplicates"""
        if not self.development_mode:
            return None
        
        try:
            # Get all feedback
            all_feedback = self.store.get_all_feedback()
            
            # Check for exact matches first
            for feedback in all_feedback:
                if (feedback.get('original_prompt', '').strip().lower() == prompt.strip().lower() and
                    feedback.get('original_response', '').strip().lower() == response.strip().lower()):
                    return feedback
            
            # If no exact match, check for very similar content using vector similarity
            similar_feedback = self.store.search_similar_feedback(prompt, limit=1)
            if similar_feedback:
                # Check if similarity is very high (indicating likely duplicate)
                return similar_feedback[0]
            
            return None
            
        except Exception as e:
            logger.error(f"Error finding similar feedback: {str(e)}")
            return None

# Create global feedback manager
feedback_manager = FeedbackManager()
